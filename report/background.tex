\chapter{Background}
This chapter will give some background on important algorithms and file formats used in this project. It will also give an introduction to the snow simulator.

\section{Search Algorithms and A* Shortest Path Search Algorithm}
Finding the shortest path between nodes in a graph is an old and heavily researched problem. The problem can be stated like this: Given a weighted graph $G = (V,E)$ with edges $E$ and vertices $V$, and a weighting function $w(e) = w(v_i, v_j)$ of edge $e = (v_i, v_j)$, find the path from $v_a$ to $v_b$, that solves the minimization problem

\begin{equation}
\min_{\mbf P} \left\{ \sum_{e\in \mbf{p}} w(e) \right\}
\end{equation}

over all paths $\mbf P$ between nodes $v_a$ and $v_b$.

\subsection{Solving shortest path problems}
There are many algorithms to solve the minimization problem of finding the shortest path. There are two main categories: Single-source, and all-pairs. Single-source solves the shortest path algorithm for a single source node $a$, to one or all other nodes. All-pairs finds, as the name suggests, the shortest path between all the nodes in the graph. In this project, we are concerned about the single-source shortest path algorithms. In particular, we are interested in finding the shortest path between one node $v_a$ to another single node $v_b$.

\subsubsection{Dijkstra's algorithm}
One of the most well known and efficient single-source algorithms when we assume that we have no knowledge of the graph, is Dijkstra's algorithm. Dijkstra's algorithm is descriped in algorithm \ref{alg:dijkstra}. The basic idea behind the algorithm is to always choose to look at the neighbors of the node currently closest to the starting node that has not yet been explored. To retrieve the actual path, we keep a pointer to the predecessor of each node, which is updated once a better path to that node has been found. 

\begin{algorithm}
\begin{algorithmic}
\STATE Initially, set the distance to the source $d(v_a)=0$ and for all other nodes $d(v_i) = \infty$.
\STATE Let $\pi(v)$ be the predecessor to node $v$; initially, $\forall v (\pi(v) = \mbox{none})$ 
\STATE Put all nodes $v_i$ in a priority queue, sorted on $d(v_i)$.
\WHILE {$|Q| > 0$}
    \STATE $v \gets \mbox{next node in Q}$
    \STATE $Q\gets Q - \{v\}$
    \FORALL{neighbors $w$ of $v$}
        \IF{$d(v)+w(v,w) < d(w)$}
            \STATE $d(w) \gets  d(v)+w(v, w)$.
            \STATE $\pi(w)\gets v$
        \ENDIF
    \ENDFOR
\ENDWHILE
\end{algorithmic}
\caption{Pseudocode for Dijkstra's algorithm}
\label{alg:dijkstra}
\end{algorithm}

After the algorithm finishes, we have the total cost of the shortest paths from the source $v_a$ to all other nodes. The time complexity, when implemented efficiently with a fibonacci heap, is $O(|E|+|V|\log |V|)$\cite{fibodijkstra}. One useful observation is that the shortest path to the node we pick from the queue is optimal; this is due to the fact that all other nodes in the queue has a larger or equal distance from $v_a$, and thus, assuming non-negative edges, we can not hope to find a better path.. Because of this, if we are only interested in the path from $v_a$ to $v_b$, we can stop the algorithm once we pick $v_b$ from the queue. 

\subsubsection{Utilizing knowledge about graph topology: A*}
In many practical cases, we have specific knowledge about the graph topology. For instance, if we seek to find the shortest path from the city of Oslo to Trondheim, we know, for instance, that if we move in the right direction (i.e. north), we are most probably closer than we were, and we know that we need to travel AT LEAST the straight line distance from Oslo to Trondheim. This kind of knowledge can be utilized in making more efficient single-source, single-destination shortest path algorithms, by computing heuristics on the cost from each node to the goal. One such algorithm is A*.\cite{astar}

A* is an extension of Dijkstra's algorithm. We define $g(x)$ as the distance from the start node $v_a$ to node $x$ ($g(x)$ is the same as $d(x)$ in Dijkstra's algorithm, but it is common to denote this function as $g(x)$ in literature). We also define the heuristic $h(x)$ as an {\textit admissive} (optimistic) and {\textit consistent} (monotone) estimate of the cost from node $x$ to the goal node $v_b$. That the heuristic is optimistic simply means that it never over-estimates the distance left to the goal, i.e. $h(x) \leq h^*(x)$, where $h^*(x)$ is the {\textit optimal} heuristic function, that give the exact cost from node $x$ to the goal node $v_b$. That the heuristic is consistent, means that the search will never take a step back. This is described later.

Combining these values gives the {\textit f-cost} $f(x) = g(x)+h(x)$, which is the actual estimate on the distance from the start node $v_a$ to the goal node $v_b$. The algorithm is outlined in algorithm \ref{alg:astar}.

\begin{algorithm}
\begin{algorithmic}
\STATE Maintain a queue $OPEN$ and a set $CLOSED$. 
\STATE Initially, $OPEN = \{v_a\}$ and $CLOSED = \emptyset$. 
\STATE Let $\pi(v)$ be the predecessor to node $v$; initially, $\forall v (\pi(v) = \mbox{none})$ 
\WHILE {$|Q| > 0 \land v_b \notin CLOSED$}
    \STATE $v \gets \mbox{node with smallest f-cost in OPEN}$
    \STATE $OPEN\gets OPEN - {v}$
    \STATE $CLOSED \gets CLOSED + \{v\}$
    \FORALL{neighbors $w$ of $v$}
        \IF{$w \notin CLOSED \land w \notin OPEN$}
            \STATE Put $w$ in the $OPEN$ queue.
        \ELSIF{$w \in OPEN \wedge g(v)+w(v,w) < g(w)$}
            \STATE $g(w) \gets g(v)+w(v,w)$
        \ENDIF
    \ENDFOR
\ENDWHILE
\end{algorithmic}
\caption{Pseudocode for A* shortest path algorithm}
\label{alg:astar}
\end{algorithm}

The main difference from the regular Dijkstra's algorithm, is how nodes are picked from the queue. Instead of picking the node with the lowest $g(x)$ as we do with Dijkstra, we pick the node with the lowest f-cost, $f(x) = g(x) + h(x)$. This way we prefer nodes that are "closer" to the goal. As a side note, if we set $h(x)=0$, the A* algorithm is reduced to Dijkstra's algorithm. If we use the example of finding the shortest route from Oslo to Trondheim, if we use Dijkstra, nodes will be expanded in all directions, i.e. Dijkstra will search both south, west and east, which is unneccesary work. If we instead use A*, nodes south of Oslo may still have a small distance from the start, but will have a higher $h(x)$ than those to the north, and thus may not be selected for expansion. Figure \ref{fig:astar_vs_dijkstra} shows the expanded nodes for a simple shortest path problem where $w(v,w)=1$ for all pairs of neighbors $v,w$, and the neighbors are the neighboring four nodes.

\begin{figure}[ht]
\centering
\subfloat[A* expansions]{\includegraphics[width=0.40\textwidth]{figure/astar_expansion}}
\qquad
\subfloat[Dijkstra expansions]{\includegraphics[width=0.40\textwidth]{figure/dijkstra_expansion}}
\caption{Expanded nodes in A* vs. Dijkstra}
\label{fig:astar_vs_dijkstra}
\end{figure}

\subsubsection{Designing the heuristic. Admissibility and consistency}
In order to guarantee that the A* algorithm is optimal, the heuristic function $h(x)$ must be admissible and consistent\cite{astar}. That $h(x)$ is admissible means that $h(x) \leq h^*(x)$ where $h^*(x)$ is the optimal heuristic that gives the exact distance to the goal from a node $x$. More intuitively, this means that $h(x)$ is an {\textit optimistic} estimate of the cost: the estimate is at most the actual cost. For pathfinding in euclidean space, e.g. in $\mathbb{R^3}$, an admissible heuristic is the straight line distance to the goal; the actual cost to the goal may, however, be higher due to obstacles.

A consistent, also called monotonic heuristic is a heuristic that fulfills the requirement $h(x) \leq w(x,y) + h(y) \Leftrightarrow h(x)-h(y) \leq w(x,y)$. This means that we will never take a step back, because the cost of getting to $y$ from $x$ is greater (or equal to) the difference in the estimates. This implies that if $x$ is the node being explored, we can never find a better $g(x)$ by going through $y$ from $x$; we will always have a monotonically increasing total cost for the best path, as the search goes on. The straight line distance in euclidean space $\mathbb{R^n}$ is a consistent heuristic for the shortest path between two points, because moving in any direction will give a greater or equal total f-cost for the path. It is equal if there is no obstacles, greater if there are, because then we are no longer moving in a straight line.

What heuristic to choose is highly dependent on the problem. For finding the optimal driving route, the euclidean distance to the goal is sufficient. This is also true for the problem of finding a trajectory through a terrain, as is the case in this project. For solving the 8-puzzle, the sum of the manhattan distances of each brick may be an acceptable heuristic. In general, a more accurate heuristic is more expensive to compute, but will also most likely be more efficient in terms of the number of nodes expanded.

\subsection{Applications of shortest path algorithms}
In general, shortest path algorithms solve the minimization problem of finding the path of least cost from a start node $v_a$ to $v_b$. Applications for such algorithms are numerous. Examples are: finding the fastest driving route given a map, finding the best route for a network packet, find the optimal solution to a particular game (e.g. Rubik's cube), and, part of what this project is about, find the best path through a terrain for generating a road trajectory. All that is required, is to express the problem as a weighted graph, and also if using A*, design an admissible and consistent heuristic. 

\section{GPU computing}
Although this project is not particularly about GPU computing, the snow simulator is real-time much because the heavy computation of simulating the wind field and updating the particle velocities and positions are implemented on the GPU. Because of that, the topic of GPU computing is still relevant for this project. This section will describe the capabilities of the GPU, its architecture, and logical layout when used for general purpose computing. We will mainly focus on NVIDIA GPUs here because that is what has been used traditionally in the snow simulator, but the concepts are transferrable to GPUs from other vendors.

\subsection{Physical layout of a GPU}
GPUs (Graphics Processing Units) are accellerators originally intended for highly efficient rendering of 3D graphics on a computer. Rendering is a highly parallel process, where each pixel can be rendered more or less independently from every other pixel. Because of this, GPUs are designed to be highly parallel devices with hundreds of simple vector cores where each vector core typically work on a single pixel. All vector cores may access a global memory with a capacity of hundreds of megabytes up to some gigabytes of memory, but there is also a faster cache available which is shared among groups of size 8 to 32 vector cores, depending on the architecture.

\subsubsection{GPU core organization and properties}
A GPU has hundreds of vector cores called {\textit streaming processor cores} (SPs). These cores are grouped into {\textit streaming multiprocessors} (SMs); each SM has between 8 to 32 SPs depending on the architecture; pre-Fermi architectures had 8, while Fermi-GPUs have 32 SPs. 

\subsubsection{Memory model}
All vector cores may access a global memory, analogous to a regular computer's main memory. However, even though the bandwidth is huge (> 100GB/s for modern NVIDIA Tesla GPUs), the latency is enormous, of hundreds of cycles. This neccessitates a closer and faster memory. On NVIDIA GPUs this memory is called \textit{shared memory}. The difference between shared memory and a traditional cache is that shared memory must be managed manually; i.e. movement of words in and out of shared memory is done explicitly in code.

\subsubsection{Improvements with Fermi}

\subsection{General purpose GPU computing}

\subsection{CUDA}

\section{Road generation}
Roads can be generated in a number of ways; city street networks can be generated using using Lindenmayer systems\cite{citymodelling}, and shortest path algoriths like A* can be used to generate roads through a terrain, and this method may even be extended to generating hierarchical roads.\cite{roadgen}\cite{roadgen2}
Generating realistic roads is more often than not non-trivial due to the many variables that determine if a road is "good" or not. For instance, different types of roads (e.g. highways, country roads) may have different tolerance to changes in elevation and curvature, and the tradeoffs of going up a steep slope or making a longer, more curvy road around that slope must be weighted. In this section we will first look at how we can formulate the problem of generating a road through a terrain as a shortest-path problem as described by \cite{roadgen}, and lastly we will discuss the details about the trajectory computation and road modelling given a discrete shortest path.
%A cost function controls the road trajectory we get

\subsection{Formulating road generation as a shortest-path problem}
Road generation can be formulated as a shortest-path problem in the following manner. First, discretize the terrain into a grid of elevation points. Each of these points is then a node in the graph. Conveniently enough, these points are also in $\mathbb{R}^3$ $(x,y,height)$, which makes designing heuristics for A* easier.

Next, we must define the edges of the graph. Those edges define, naturally, which nodes that can be reached from each node. The most naive ways of defining this neighborhood is either to choose ALL nodes to be reachable from every other node, or only the immediate 8 neighbors. The first approach would be computationally infeasible due to the sheer amount of nodes in the graph. The other approach has a severe restriction on angles (the so-called limit on direction problem\cite{roadgen}), as the pathfinding algorithm can only take turns in multiples of 45 degrees, resulting in a fairly jagged path. 

The solution to this problem of limit on direction, as presented in\cite{roadgen}, is to not only use the immediate neighbors, but use a neighborhood mask to define the neighbors. This mask is defined as follows: The neighbors of a point $p_{k,l}$ is defined as all points $p_{k+i,l+j}$ where $i,j$ is integers, $gcd(i,j) = 1$ and $i,j \in [-k,k]$. That $gcd(i,j)=1$ requirement is not a requirement for correctness, but to avoid unneccesary cost function evaluations for overlapping paths. Figure \ref{fig:neighbormask} illustrates the neighborhood of a grid point with a mask size of $k=2$.

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{figure/neighbormask}
\caption{Neighborhood of grid point (middle).}
\label{fig:neighbormask}
\end{figure}

In order to define the weights of each edge, we define the cost of building an infinitesimal portion of road from point ${\mbf p}$, in the direction $\dot{\mbf p}$ and rate of change of the direction $\ddot{\mbf p}$ as $c({\mbf p}, \dot{{\mbf p}}, \ddot{{\mbf p}})$. Now, in order to evaluate the cost of a particular trajectory, simply integrate over the curve as shown in equation \ref{eq:roadcost}. Here, $t_1$ and $t_2$ define the segment end points of the parametric curve defined by the whole trajectory, as illustrated in figure \ref{fig:trajectory_segment}. $t_1$ and $t_2$ correspond to the grid points ${\mbf p}_{i_1,j_1}$ and ${\mbf p}_{i_2,j_2}$, respectively.

\begin{equation}
cost({\mbf p}_{i_1,j_1}, {\mbf p}_{i_2,j_2}) = \int_{t_1}^{t_2} c({\mbf p}(t), \dot{{\mbf p}}(t), \ddot{{\mbf p}})(t) dt
\label{eq:roadcost}
\end{equation}

Evaluating this integral can be done numerically by discretizing the curve into intervals of length $\Delta t$ and using some numerical integration method like the midpoint rule or Simpson's rule.

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{figure/trajectory_segment}
\caption{Trajectory segment}
\label{fig:trajectory_segment}
\end{figure}

\subsection{Cost functions}
There are many potential contributing factors to the cost of a trajectory. One of them is of course road length, where the cost typically increases linearly with the length. In order to get realistic roads, however, using only road length as a cost function is not sufficient, because that would simply generate a nearly straight line from start to goal, which is suboptimal in e.g. a mountainous terrain. Adding an extra cost for slopes, or change in elevation, will cause the road to have curves around steep mountain sides, and roads will generally avoid bumpy terrain. However, this may result in sharp turns because curvature is not taken into account when attempting to avoid elevation changes. This may be alleviated by also taking curvature into account.

Let each of the cost functions, for road length, elevation changes and curvature, and possibly more, be numbered $1, ..., n$ where $n$ is the number of cost functions. Also, let $\mu_i$ be a {\textit transfer function} that maps the measured values of slope, curvature and so on, to the actual cost value. It may be helpful to think of $\mu_i$ as a weighting function, although it may also be unlinear. Then, the cost function can be defined as
$$
C({\mbf p}, \dot{{\mbf p}}, \ddot{\mbf{p}}) = \sum_{i=1}^{n} \mu_i(c_i({\mbf p}, \dot{{\mbf p}}, \ddot{\mbf{p}}))
$$

\subsection{Trajectory computation}

\subsection{Road model generation}


\section{Clothoids and clothoid splines}

\section{Simulating snow}
A major part of this project is to extending the snow simulator developed at the HPC lab at NTNU, to support loading meshes (mainly roads, but may be arbitrary meshes). In order to fully integrate the contributions from this project into the snow simulator, it is important to have some background on the way the snow simulator works. This section will first describe how the wind simulation is done, and then go into details of how the particles are updated. 

%Also, a few other improvements, discussed in section \ref{sec:impl_snowsim}, have been done. 

\subsection{Terrain}

\subsection{Wind simulation}

\subsubsection{Modelling wind as a fluid}

\subsubsection{Obstacles}

\subsubsection{}

\subsection{Particle updates}

\section{USGS DEM Format}
USGS DEM is a file format for storing elevation data. It is a format in human readable ASCII characters, and the files are segmented into blocks of 1024 bytes. There are three types of records in a DEM file: one A-record, which is the header; multiple B-records, where each B-record store one column of elevation data and one C-record, which stores statistics of errors and accuracy of the data.\cite{usgsdem}

The data in a DEM is defined for a quadrangle; i.e. an arbitrary polygon of four vertices. The quadrangle may or may not be an axis-aligned rectangle, but most likely it will be {\textit close} to a rectangle. Oftentimes, the quadrangle attempts to follow the curvature of the earth mapped onto a plane, which gives slightly rotated and skewed rectangles.

Next, I will give an overview of the A and B records of a DEM. The C-record is not relevant for this project.

\subsection{A-record overview}
The A-record is the header of the DEM file, containing data such as the vertices of the quadrangle in world coordinates, total number of columns of data, minimum and maximum elevation in the DEM, units used for the quantities in the file (feet, meters, arc seconds), and so on. It also stores information about resolution in all three dimensions. 

\subsection{B-record overview}
\label{sec:back_brecord}
Each B-record stores one column of data for the height map along with a header for this data. However, since the quadrangle stored in a DEM file may not be quadratic, each column may have different number of elements. The position of the bottom-most point is specified in the header in world coordinates, along with the number of points. One B-block may span more than one 1024-byte block.

Each elevation data point in the B-record is stored as an integer, and may be converted to an actual height value $h_i$ (in meters) by using the following formula for datapoint $y_i$:
$$
h_i = ((e_{max}-e_{min})\cdot y_i+ d_y)\cdot res_y \cdot unit
$$

where $d_y$ is the height datum and $e_{max}$ and $e_{min}$ is the maximum and minimum elevation, respectively. $unit$ is the number of meters per unit specified in the A-record; $unit=1$ for meters, or $0.3048$ for feet.

Details about the layout of the USGS DEM file format can be found in appendix \ref{app:usgsdem}.

\section{RoadXML}
The RoadXML format is an XML based file format used to describe road networks. In addition to describing the trajectories, it also describes the profile of the road (i.e. width, markings, number of lanes, ...) and textures used for rendering.\cite{roadxml} RoadXML is an open format, developed in collaboration with the driving simulation industry and universities. Although RoadXML is a very powerful and extensive format used to describe complex systems with intersections, traffic information, grip, and much more, it is in this project only used as a road trajectory descriptor suitable for generating the road model.


